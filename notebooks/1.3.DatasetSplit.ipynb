{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Split\n",
    "\n",
    "- Read the Dataset\n",
    "- Split into Train and Test\n",
    "- Store the split into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['HD_ChR2_480A', 'HD_ChR2_510A', 'HD_ChR2_586A', 'HD_YFP_037A',\n",
       "        'HD_YFP_443A', 'HD_YFP_463A', 'WT_ChR2_087A', 'WT_ChR2_400A',\n",
       "        'WT_ChR2_425A', 'WT_ChR2_635A', 'WT_ChR2_654A', 'WT_YFP_154A',\n",
       "        'WT_YFP_435A', 'WT_YFP_535A', 'WT_YFP_602A', 'WT_YFP_741A',\n",
       "        'WT_YFP_792', '1', '2', '3', '4', '5', 'Animal61980',\n",
       "        'Animal62418'], dtype='<U12'),\n",
       " array(['HD_ChR2_480A.csv', 'HD_ChR2_510A.csv', 'HD_ChR2_586A.csv',\n",
       "        'HD_YFP_037A.csv', 'HD_YFP_443A.csv', 'HD_YFP_463A.csv',\n",
       "        'WT_ChR2_087A.csv', 'WT_ChR2_400A.csv', 'WT_ChR2_425A.csv',\n",
       "        'WT_ChR2_635A.csv', 'WT_ChR2_654A.csv', 'WT_YFP_154A.csv',\n",
       "        'WT_YFP_435A.csv', 'WT_YFP_535A.csv', 'WT_YFP_602A.csv',\n",
       "        'WT_YFP_741A.csv', 'WT_YFP_792.csv', '1.csv', '2.csv', '3.csv',\n",
       "        '4.csv', '5.csv', 'Animal61980.csv', 'Animal62418.csv'],\n",
       "       dtype='<U16'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset folders\n",
    "dataset_path = '../data/processed/ImageDatasetRGB'\n",
    "#dataset_path = '../data/NewProcessed/ImageDatasetRGB'\n",
    "\n",
    "features = np.array(sorted(os.listdir(os.path.join(dataset_path, 'features'))))\n",
    "labels = np.array(sorted(os.listdir(os.path.join(dataset_path, 'labels'))))\n",
    "\n",
    "# If DS_Store, remove it\n",
    "if '.DS_Store' or 'DS_Store' in features:\n",
    "    features = np.delete(features, 0)\n",
    "    features = np.delete(features, 0)\n",
    "if '.DS_Store' or'DS_Store' in labels:\n",
    "    labels = np.delete(labels, 0)\n",
    "    labels = np.delete(labels, 0)\n",
    "\n",
    "\n",
    "dataset_path = '../data/NewProcessed/ImageDatasetRGB'\n",
    "\n",
    "features = np.concatenate((features,sorted(os.listdir(os.path.join(dataset_path, 'features')))))\n",
    "labels = np.concatenate((labels,sorted(os.listdir(os.path.join(dataset_path, 'labels')))))\n",
    "\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  [ 6  7 21  1 16  0 15 23 22  9  8 12 11  5]\n",
      "Test set:  [10 20 13 14 18  4  2 17]\n",
      "Validation set:  [ 3 19]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "random.seed(10) # Fix a seed\n",
    "\n",
    "# Split train-test\n",
    "indices_train, indices_test = train_test_split(np.arange(len(features)), test_size=0.4, random_state=1)\n",
    "# Split test-validation\n",
    "indices_test, indices_validation = train_test_split(indices_test, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "print('Train set: ', indices_train)\n",
    "print('Test set: ',indices_test)\n",
    "print('Validation set: ',indices_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a destination folder to store the data\n",
    "dataset_path = '../data/processed/NewDataset'\n",
    "os.mkdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'train', 'test', 'validation', 'test', 'train', 'train', 'train', 'train', 'train', 'test', 'train', 'train', 'test', 'test', 'train', 'train', 'test', 'test', 'validation', 'test', 'train', 'train', 'train']\n"
     ]
    }
   ],
   "source": [
    "set_list = []\n",
    "\n",
    "for i in  np.arange(len(features)):\n",
    "    if i in indices_validation:\n",
    "        set_list.append('validation')\n",
    "    elif i in indices_test:\n",
    "        set_list.append('test')\n",
    "    else:\n",
    "        set_list.append('train')\n",
    "\n",
    "print(set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = pd.DataFrame({\n",
    "    'name': features,\n",
    "    'set': set_list\n",
    "})\n",
    "dataset_split.to_csv(os.path.join(dataset_path, 'split.csv'), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "79da1f634b9d48f5768811b03fe06bbb63e4e3154741404ab553ecc445a12d48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
