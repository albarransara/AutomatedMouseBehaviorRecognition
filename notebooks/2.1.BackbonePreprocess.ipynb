{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbone Preprocessing\n",
    "\n",
    "- Define a feature extractor model using one of the backbones: ResNet50, InceptionResnetV2\n",
    "- Read the image dataset and run the model on each image\n",
    "- Store the output into the corresponding folder: backbone, train or test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the feature extractor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(tf.keras.Model):\n",
    "    def __init__(self, model_name):\n",
    "        \"\"\"\n",
    "            Initialize Feature extractor with a pretrained CNN model\n",
    "\n",
    "            Args:\n",
    "                model_name: name of the pretrained CNN model [\"resnet\", \"inception_resnet\"]\n",
    "        \"\"\"\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        if model_name == \"resnet\":\n",
    "            from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "            self.model = ResNet50V2(include_top=False, weights='imagenet', pooling='avg')\n",
    "            self.model_input_size = (224, 224)\n",
    "        elif model_name == \"inception_resnet\":\n",
    "            from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "            self.model = InceptionResNetV2(include_top=False, weights='imagenet', pooling='avg')\n",
    "            self.model_input_size = (299, 299)\n",
    "        else:\n",
    "            raise NameError('Invalid pretrained model name - must be one of [\"resnet\", \"inception_resnet\"]')\n",
    "        \n",
    "        self.preprocess_input = preprocess_input\n",
    "        self.model.trainable = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "            Call the pretrained CNN model to predict the features for a given input image\n",
    "\n",
    "            Args:\n",
    "                inputs: input image tensor\n",
    "        \"\"\"\n",
    "        # Resize inputs to the expected input size\n",
    "        inputs = inputs*255\n",
    "        inputs = tf.image.resize(inputs, self.model_input_size)\n",
    "        inputs = inputs[tf.newaxis, :]\n",
    "        preprocessed_input = self.preprocess_input(inputs)\n",
    "        return self.model.predict(preprocessed_input).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input and output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset input and output folders\n",
    "image_dataset_path = '../data/processed/ImageDatasetRGB'\n",
    "dataset_path = '../data/processed/Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = sorted(os.listdir(os.path.join(image_dataset_path, 'features')))\n",
    "labels = sorted(os.listdir(os.path.join(image_dataset_path, 'labels')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = pd.read_csv(os.path.join(dataset_path, 'split.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor('resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_path = os.path.join(dataset_path, 'resnet')\n",
    "os.mkdir(resnet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(resnet_path, 'train'))\n",
    "os.mkdir(os.path.join(resnet_path, 'train', 'features'))\n",
    "os.mkdir(os.path.join(resnet_path, 'train', 'labels'))\n",
    "os.mkdir(os.path.join(resnet_path, 'test'))\n",
    "os.mkdir(os.path.join(resnet_path, 'test', 'features'))\n",
    "os.mkdir(os.path.join(resnet_path, 'test', 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video, label in zip(videos, labels):\n",
    "    features = []\n",
    "    for frame_name in sorted(os.listdir(os.path.join(image_dataset_path, 'features', video))):\n",
    "        frame = tf.io.read_file(os.path.join(image_dataset_path, 'features', video, frame_name))\n",
    "        frame = tf.image.decode_image(frame, channels=3)\n",
    "        frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "        features.append(feature_extractor(frame))\n",
    "\n",
    "    video_features = np.array(features)\n",
    "    video_labels = pd.read_csv(os.path.join(image_dataset_path, 'labels', label))\n",
    "\n",
    "    if split[split['name'] == video]['set'].values == 'train':\n",
    "        output_folder = os.path.join(resnet_path, 'train')\n",
    "    else:\n",
    "        output_folder = os.path.join(resnet_path, 'test')\n",
    "    np.save(os.path.join(output_folder, 'features', video + '.npy'), video_features)\n",
    "    video_labels.to_csv(os.path.join(output_folder, 'labels', video + '.csv'), index=None)\n",
    "    print('.', end='')\n",
    "    \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionResNet Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor('inception_resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_resnet_path = os.path.join(dataset_path, 'inception_resnet')\n",
    "os.mkdir(inception_resnet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(inception_resnet_path, 'train'))\n",
    "os.mkdir(os.path.join(inception_resnet_path, 'train', 'features'))\n",
    "os.mkdir(os.path.join(inception_resnet_path, 'train', 'labels'))\n",
    "os.mkdir(os.path.join(inception_resnet_path, 'test'))\n",
    "os.mkdir(os.path.join(inception_resnet_path, 'test', 'features'))\n",
    "os.mkdir(os.path.join(inception_resnet_path, 'test', 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video, label in zip(videos, labels):\n",
    "    features = []\n",
    "    for frame_name in sorted(os.listdir(os.path.join(image_dataset_path, 'features', video))):\n",
    "        frame = tf.io.read_file(os.path.join(image_dataset_path, 'features', video, frame_name))\n",
    "        frame = tf.image.decode_image(frame, channels=3)\n",
    "        frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "        features.append(feature_extractor(frame))\n",
    "\n",
    "    video_features = np.array(features)\n",
    "    video_labels = pd.read_csv(os.path.join(image_dataset_path, 'labels', label))\n",
    "\n",
    "    if split[split['name'] == video]['set'].values == 'train':\n",
    "        output_folder = os.path.join(inception_resnet_path, 'train')\n",
    "    else:\n",
    "        output_folder = os.path.join(inception_resnet_path, 'test')\n",
    "    np.save(os.path.join(output_folder, 'features', video + '.npy'), video_features)\n",
    "    video_labels.to_csv(os.path.join(output_folder, 'labels', video + '.csv'), index=None)\n",
    "    print('.', end='')\n",
    "    \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79da1f634b9d48f5768811b03fe06bbb63e4e3154741404ab553ecc445a12d48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
