{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "On this notebook we will:\n",
    "- Split the videos into its frames and crop them using the midbody position\n",
    "- Extract the labels from the DeepLabCutFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and create the source and destination folders\n",
    "videos_src_folder = '../data/raw/NewVideos'\n",
    "csvs_src_folder = '../data/raw/NewCSVS'\n",
    "dataset_dest_folder = '../data/NewProcessed/ImageDatasetRGB'\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(os.path.dirname(dataset_dest_folder)):\n",
    "        os.mkdir(dataset_dest_folder)\n",
    "        os.mkdir(os.path.join(dataset_dest_folder, 'features'))\n",
    "        os.mkdir(os.path.join(dataset_dest_folder, 'labels'))    \n",
    "\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "    print('Dataset Destination Folders already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content from the source folders\n",
    "csvs = sorted(os.listdir(csvs_src_folder))\n",
    "videos = sorted(os.listdir(videos_src_folder))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '.DS_Store' or 'DS_Store' in csvs:\n",
    "    csvs = np.delete(csvs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.csv', '2.csv', '3.csv', '4.csv', '5.csv', 'Animal61980.csv',\n",
       "       'Animal62418.csv'], dtype='<U15')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.mp4',\n",
       " '2.mp4',\n",
       " '3.mp4',\n",
       " '4.mp4',\n",
       " '5.mp4',\n",
       " 'Video_Animal61980_10min.mp4',\n",
       " 'Video_Animal62418_10min.mp4']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a method to automatically find the central position of the mouse and crop the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, expansion):\n",
    "    \n",
    "    # Start by converting the image to Gray scale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Rescale the values to highlight constrasted areas\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Crop the box\n",
    "    thresh2 = np.invert(thresh)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    close = cv2.morphologyEx(thresh2, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    \n",
    "    # We want to avoid noise, for that we will just consider the biggest countour since it is going to be the box\n",
    "    c = 0\n",
    "    c_len = len(cnts[0])\n",
    "    for i in range(len(cnts[1:])):\n",
    "        if len(cnts[i]) > c_len:\n",
    "            c = i\n",
    "            c_len = len(cnts[i])          \n",
    "    \n",
    "    # Obtain bounding rectangle to get the box coordinates\n",
    "    x,y,w,h = cv2.boundingRect(cnts[c])\n",
    "\n",
    "    # If the box is way to big, we won't need to crop it, else we will \n",
    "    # If the box isnot detected by the filter, then we can consider it is big enough to not crop it\n",
    "    if not (x+w - x) < image.shape[0]//4:\n",
    "        image = image[y:y+h, x:x+w]\n",
    "        thresh = thresh[y:y+h, x:x+w]\n",
    "\n",
    "    # We can now look for the mouse contour\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "   \n",
    "    # We want to avoid noise, for that we will just consider the biggest countour since it is going to be the mouse, as long as it is not\n",
    "    # to close to the extremes of the image, since that would mean it is an external object\n",
    "    c = 0\n",
    "    c_len = len(cnts[0])\n",
    "    for i in range(len(cnts[1:])):\n",
    "        if len(cnts[i]) > c_len:\n",
    "            # Obtain bounding rectangle to get measurements\n",
    "            x,y,w,h = cv2.boundingRect(cnts[i])\n",
    "            if not (y < 100) or not (y+h > image.shape[0]-100):\n",
    "                c = i\n",
    "                c_len = len(cnts[i])\n",
    "\n",
    "    # Crate a bounding box arround the mouse\n",
    "    x,y,w,h = cv2.boundingRect(cnts[c])\n",
    "    \n",
    "    # Find centroid, this will be the center position of the mouse\n",
    "    M = cv2.moments(cnts[c])            \n",
    "    cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-10))\n",
    "    cY = int(M[\"m01\"] / (M[\"m00\"]+ 1e-10))\n",
    "    midbody = [cX,cY]\n",
    "    top = max(0, midbody[0] - expansion) - max(0, midbody[0] + expansion - image.shape[0])\n",
    "    bottom = min(image.shape[0], midbody[0] + expansion) + max(0, expansion - midbody[0])\n",
    "    left = max(0, midbody[1] - expansion) - max(0, midbody[1] + expansion - image.shape[1])\n",
    "    right = min(image.shape[1], midbody[1] + expansion) + max(0, expansion - midbody[1])\n",
    "   \n",
    "    return image[left:right,top:bottom]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can start processing the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.mp4\n",
      "1.csv\n",
      "DF:  (10884, 2)\n",
      "Video FPS:  29.97\n",
      "Label rows:  (3631, 2)\n",
      "Video frames:  3631\n",
      "2.mp4\n",
      "2.csv\n",
      "DF:  (12055, 2)\n",
      "Video FPS:  29.97\n",
      "Label rows:  (4022, 2)\n",
      "Video frames:  4022\n",
      "3.mp4\n",
      "3.csv\n",
      "DF:  (12795, 2)\n",
      "Video FPS:  29.97\n",
      "Label rows:  (4268, 2)\n",
      "Video frames:  4269\n",
      "4.mp4\n",
      "4.csv\n",
      "DF:  (13558, 2)\n",
      "Video FPS:  29.97\n",
      "Label rows:  (4523, 2)\n",
      "Video frames:  4524\n",
      "5.mp4\n",
      "5.csv\n",
      "DF:  (12178, 2)\n",
      "Video FPS:  29.97\n",
      "Label rows:  (4063, 2)\n",
      "Video frames:  4063\n",
      "Video_Animal61980_10min.mp4\n",
      "Animal61980.csv\n",
      "DF:  (6000, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6000, 2)\n",
      "Video frames:  6000\n",
      "Video_Animal62418_10min.mp4\n",
      "Animal62418.csv\n",
      "DF:  (6000, 2)\n",
      "Video FPS:  10.0\n",
      "Label rows:  (6000, 2)\n",
      "Video frames:  6000\n"
     ]
    }
   ],
   "source": [
    "expansion = 80\n",
    "behaviours = ['Grooming', 'Rearing']\n",
    "fps = 10\n",
    "\n",
    "for csv, video in zip(csvs, videos):\n",
    "\n",
    "    print(video)\n",
    "    \n",
    "    # Read columns from csvs corresponding to the behaviours\n",
    "    df = pd.read_csv(os.path.join(csvs_src_folder, csv), header=0, usecols = behaviours)\n",
    "    # Change voids per 0 \n",
    "    df.fillna(0, inplace=True)\n",
    "    # Change data format\n",
    "    df = df.astype(int)\n",
    "    # Reset row indexes\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    # Save df as csv\n",
    "    df.to_csv(os.path.join(dataset_dest_folder, 'labels', csv.split('.')[0] + '.csv'), index=False)\n",
    "    print(csv)\n",
    "    print('DF: ', df.shape)\n",
    "\n",
    "    # Get video frames\n",
    "    os.mkdir(os.path.join(dataset_dest_folder, 'features', csv.split('.')[0]))\n",
    "    vidcap = cv2.VideoCapture(os.path.join(videos_src_folder, video))              \n",
    "\n",
    "    # Get the video FPS rate\n",
    "    fps_in = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    print('Video FPS: ', fps_in)\n",
    "\n",
    "    # Start processing each frame\n",
    "    success,image = vidcap.read()\n",
    "\n",
    "    frames_in = 0\n",
    "    frames_out = 0\n",
    "    count = 0\n",
    "    count_df = 0\n",
    "    drop_indx = []\n",
    "    \n",
    "    while success:\n",
    "        #If the video already has the standard FPS, we don't have to do anything \n",
    "        if  fps_in == fps:\n",
    "            # Build frame name\n",
    "            frame_name = 'frame'\n",
    "            for i in range(4-len(str(count))):\n",
    "                frame_name += '0'\n",
    "            frame_name += str(count) + '.jpg'\n",
    "    \n",
    "            # Crop image so mouse is postioned in the center\n",
    "            frame = crop_image(image, expansion)\n",
    "            \n",
    "            # Save frame\n",
    "            cv2.imwrite(os.path.join(dataset_dest_folder, 'features', csv.split('.')[0], frame_name), frame)\n",
    "            \n",
    "            success, image = vidcap.read()\n",
    "            count += 1\n",
    "        # Else we will adjsut the frames we process so we get the standard FPS rate\n",
    "        else:\n",
    "            # We will caluculate the second where we are on the video and scale it to the desired FPS\n",
    "            out_due = int(frames_in / fps_in * fps)\n",
    "    \n",
    "            if out_due > frames_out:\n",
    "                frames_out += 1\n",
    "                # Build frame name\n",
    "                frame_name = 'frame'\n",
    "                for i in range(4-len(str(count))):\n",
    "                    frame_name += '0'\n",
    "                frame_name += str(count) + '.jpg'\n",
    "        \n",
    "                # Crop image so mouse is postioned in the center\n",
    "                frame = crop_image(image, expansion)\n",
    "                \n",
    "                # Save frame\n",
    "                cv2.imwrite(os.path.join(dataset_dest_folder, 'features', csv.split('.')[0], frame_name), frame) \n",
    "                count += 1  \n",
    "            # We will remove those rows that don't correspond to any frame\n",
    "            else:\n",
    "                if count_df < len(df):\n",
    "                    drop_indx.append(count_df)\n",
    "\n",
    "            success, image = vidcap.read()\n",
    "            frames_in += 1\n",
    "            count_df += 1\n",
    "            \n",
    "    if  fps_in != fps:\n",
    "        df = df.drop(drop_indx, axis=0)\n",
    "        # Save df as csv\n",
    "        df.to_csv(os.path.join(dataset_dest_folder, 'labels', csv.split('.')[0] + '.csv'), index=False)\n",
    "        \n",
    "    print(\"Label rows: \", df.shape)\n",
    "    print(\"Video frames: \", count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "79da1f634b9d48f5768811b03fe06bbb63e4e3154741404ab553ecc445a12d48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
